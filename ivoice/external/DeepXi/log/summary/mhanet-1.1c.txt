Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 inp (InputLayer)               [(None, None, 257)]  0           []                               
                                                                                                  
 conv1d (Conv1D)                (None, None, 256)    65792       ['inp[0][0]']                    
                                                                                                  
 layer_normalization (LayerNorm  (None, None, 256)   512         ['conv1d[0][0]']                 
 alization)                                                                                       
                                                                                                  
 re_lu (ReLU)                   (None, None, 256)    0           ['layer_normalization[0][0]']    
                                                                                                  
 tf.compat.v1.shape (TFOpLambda  (3,)                0           ['re_lu[0][0]']                  
 )                                                                                                
                                                                                                  
 tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     
 ingOpLambda)                                                                                     
                                                                                                  
 tf.compat.v1.shape_1 (TFOpLamb  (3,)                0           ['re_lu[0][0]']                  
 da)                                                                                              
                                                                                                  
 tf.range (TFOpLambda)          (None,)              0           ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
 tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.compat.v1.shape_1[0][0]']   
 icingOpLambda)                                                                                   
                                                                                                  
 tf.tile (TFOpLambda)           (None, None)         0           ['tf.range[0][0]',               
                                                                  'tf.__operators__.getitem_1[0][0
                                                                 ]']                              
                                                                                                  
 embedding (Embedding)          (None, None, 256)    524288      ['tf.tile[0][0]']                
                                                                                                  
 add (Add)                      (None, None, 256)    0           ['re_lu[0][0]',                  
                                                                  'embedding[0][0]']              
                                                                                                  
 attention_mask_v2 (AttentionMa  (None, 1, None, Non  0          ['inp[0][0]']                    
 skV2)                          e)                                                                
                                                                                                  
 multi_head_attention (MultiHea  (None, None, 256)   262144      ['add[0][0]',                    
 dAttention)                                                      'add[0][0]',                    
                                                                  'add[0][0]',                    
                                                                  'attention_mask_v2[0][0]']      
                                                                                                  
 add_1 (Add)                    (None, None, 256)    0           ['add[0][0]',                    
                                                                  'multi_head_attention[0][0]']   
                                                                                                  
 layer_normalization_1 (LayerNo  (None, None, 256)   512         ['add_1[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 conv1d_1 (Conv1D)              (None, None, 1024)   263168      ['layer_normalization_1[0][0]']  
                                                                                                  
 re_lu_1 (ReLU)                 (None, None, 1024)   0           ['conv1d_1[0][0]']               
                                                                                                  
 conv1d_2 (Conv1D)              (None, None, 256)    262400      ['re_lu_1[0][0]']                
                                                                                                  
 add_2 (Add)                    (None, None, 256)    0           ['layer_normalization_1[0][0]',  
                                                                  'conv1d_2[0][0]']               
                                                                                                  
 layer_normalization_2 (LayerNo  (None, None, 256)   512         ['add_2[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_1 (MultiH  (None, None, 256)   262144      ['layer_normalization_2[0][0]',  
 eadAttention)                                                    'layer_normalization_2[0][0]',  
                                                                  'layer_normalization_2[0][0]',  
                                                                  'attention_mask_v2[0][0]']      
                                                                                                  
 add_3 (Add)                    (None, None, 256)    0           ['layer_normalization_2[0][0]',  
                                                                  'multi_head_attention_1[0][0]'] 
                                                                                                  
 layer_normalization_3 (LayerNo  (None, None, 256)   512         ['add_3[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 conv1d_3 (Conv1D)              (None, None, 1024)   263168      ['layer_normalization_3[0][0]']  
                                                                                                  
 re_lu_2 (ReLU)                 (None, None, 1024)   0           ['conv1d_3[0][0]']               
                                                                                                  
 conv1d_4 (Conv1D)              (None, None, 256)    262400      ['re_lu_2[0][0]']                
                                                                                                  
 add_4 (Add)                    (None, None, 256)    0           ['layer_normalization_3[0][0]',  
                                                                  'conv1d_4[0][0]']               
                                                                                                  
 layer_normalization_4 (LayerNo  (None, None, 256)   512         ['add_4[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_2 (MultiH  (None, None, 256)   262144      ['layer_normalization_4[0][0]',  
 eadAttention)                                                    'layer_normalization_4[0][0]',  
                                                                  'layer_normalization_4[0][0]',  
                                                                  'attention_mask_v2[0][0]']      
                                                                                                  
 add_5 (Add)                    (None, None, 256)    0           ['layer_normalization_4[0][0]',  
                                                                  'multi_head_attention_2[0][0]'] 
                                                                                                  
 layer_normalization_5 (LayerNo  (None, None, 256)   512         ['add_5[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 conv1d_5 (Conv1D)              (None, None, 1024)   263168      ['layer_normalization_5[0][0]']  
                                                                                                  
 re_lu_3 (ReLU)                 (None, None, 1024)   0           ['conv1d_5[0][0]']               
                                                                                                  
 conv1d_6 (Conv1D)              (None, None, 256)    262400      ['re_lu_3[0][0]']                
                                                                                                  
 add_6 (Add)                    (None, None, 256)    0           ['layer_normalization_5[0][0]',  
                                                                  'conv1d_6[0][0]']               
                                                                                                  
 layer_normalization_6 (LayerNo  (None, None, 256)   512         ['add_6[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_3 (MultiH  (None, None, 256)   262144      ['layer_normalization_6[0][0]',  
 eadAttention)                                                    'layer_normalization_6[0][0]',  
                                                                  'layer_normalization_6[0][0]',  
                                                                  'attention_mask_v2[0][0]']      
                                                                                                  
 add_7 (Add)                    (None, None, 256)    0           ['layer_normalization_6[0][0]',  
                                                                  'multi_head_attention_3[0][0]'] 
                                                                                                  
 layer_normalization_7 (LayerNo  (None, None, 256)   512         ['add_7[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 conv1d_7 (Conv1D)              (None, None, 1024)   263168      ['layer_normalization_7[0][0]']  
                                                                                                  
 re_lu_4 (ReLU)                 (None, None, 1024)   0           ['conv1d_7[0][0]']               
                                                                                                  
 conv1d_8 (Conv1D)              (None, None, 256)    262400      ['re_lu_4[0][0]']                
                                                                                                  
 add_8 (Add)                    (None, None, 256)    0           ['layer_normalization_7[0][0]',  
                                                                  'conv1d_8[0][0]']               
                                                                                                  
 layer_normalization_8 (LayerNo  (None, None, 256)   512         ['add_8[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_4 (MultiH  (None, None, 256)   262144      ['layer_normalization_8[0][0]',  
 eadAttention)                                                    'layer_normalization_8[0][0]',  
                                                                  'layer_normalization_8[0][0]',  
                                                                  'attention_mask_v2[0][0]']      
                                                                                                  
 add_9 (Add)                    (None, None, 256)    0           ['layer_normalization_8[0][0]',  
                                                                  'multi_head_attention_4[0][0]'] 
                                                                                                  
 layer_normalization_9 (LayerNo  (None, None, 256)   512         ['add_9[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 conv1d_9 (Conv1D)              (None, None, 1024)   263168      ['layer_normalization_9[0][0]']  
                                                                                                  
 re_lu_5 (ReLU)                 (None, None, 1024)   0           ['conv1d_9[0][0]']               
                                                                                                  
 conv1d_10 (Conv1D)             (None, None, 256)    262400      ['re_lu_5[0][0]']                
                                                                                                  
 add_10 (Add)                   (None, None, 256)    0           ['layer_normalization_9[0][0]',  
                                                                  'conv1d_10[0][0]']              
                                                                                                  
 layer_normalization_10 (LayerN  (None, None, 256)   512         ['add_10[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 conv1d_11 (Conv1D)             (None, None, 257)    66049       ['layer_normalization_10[0][0]'] 
                                                                                                  
 activation (Activation)        (None, None, 257)    0           ['conv1d_11[0][0]']              
                                                                                                  
==================================================================================================
Total params: 4,600,321
Trainable params: 4,600,321
Non-trainable params: 0
__________________________________________________________________________________________________
